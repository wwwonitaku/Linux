name: AHiHi -> CF (Audio Sync Optimized)

on:
  workflow_dispatch:
    inputs:
      slug: { required: true }
      token: { required: true }
      page: { required: true }
      account: { required: true }
      link_video:
        description: "Original video link"
        required: true
      link_audio_video:
        description: "Narration video ID"
        required: true

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: '21'

      - name: Setup Python
        run: |
          sudo apt update
          sudo apt install -y ffmpeg curl git jq unzip python3 python3-pip
          python3 -m pip install --upgrade pip
          python3 -m pip install numpy scipy librosa soundfile

      - name: Download abyss-dl.jar
        run: |
          mkdir -p tools
          curl -L -o tools/abyss-dl.jar \
            https://github.com/abdlhay/AbyssVideoDownloader/releases/latest/download/abyss-dl.jar

      - name: Download original video
        run: |
          ffmpeg -y -i "${{ github.event.inputs.link_video }}" \
            -c copy -bsf:a aac_adtstoasc original.mp4

      - name: Download narration video (abyss-dl)
        run: |
          java -jar tools/abyss-dl.jar \
            "${{ github.event.inputs.link_audio_video }}" l -o narration.mp4

      - name: Extract audio
        run: |
          ffmpeg -y -i original.mp4  -ac 1 -ar 16000 original.wav
          ffmpeg -y -i narration.mp4 -ac 1 -ar 16000 narration.wav

      - name: Align audio & build final track (Smart Multi-Anchor)
        run: |
          python3 <<'EOF'
          import librosa, numpy as np, soundfile as sf
          from scipy.signal import correlate

          SR = 16000
          CHUNK_SEC = 10  # Kiểm tra từng đoạn 10 giây
          STEP_SEC = 5    # Nhảy bước 5 giây
          SEARCH_MARGIN = 40 # Tìm kiếm trong phạm vi +/- 40s so với vị trí tương đối

          def log(msg):
              print(f"[DEBUG] {msg}")

          # ===== LOAD =====
          log("Loading files...")
          orig_raw, _ = librosa.load("original.wav", sr=SR)
          nar_raw,  _ = librosa.load("narration.wav", sr=SR)

          # Tạo envelope để so khớp (giúp bỏ qua sự khác biệt về giọng nói, tập trung vào môi trường/nhạc)
          def get_env(y):
              return librosa.resample(np.abs(y), orig_sr=SR, target_sr=400)

          log("Processing envelopes...")
          ENV_SR = 400
          env_o = get_env(orig_raw)
          env_n = get_env(nar_raw)

          win = CHUNK_SEC * ENV_SR
          step = STEP_SEC * ENV_SR
          margin = SEARCH_MARGIN * ENV_SR

          final_audio = orig_raw.copy()
          weights = np.zeros_like(orig_raw)
          
          last_o_idx = 0
          anchors_found = 0

          log("Scanning for anchors...")
          for i in range(0, len(env_n) - win, step):
              chunk = env_n[i : i + win]
              
              # Xác định vùng tìm kiếm xung quanh vị trí hiện tại
              search_start = max(last_o_idx, i - margin)
              search_end = min(len(env_o), i + margin + win)
              
              if search_end - search_start < win: continue
              
              search_area = env_o[search_start : search_end]
              corr = correlate(search_area, chunk, mode='valid')
              
              if len(corr) == 0: continue
              
              best_local_idx = np.argmax(corr)
              best_o_idx = search_start + best_local_idx
              
              # Độ tin cậy (Correlation score) - có thể tinh chỉnh ngưỡng nếu cần
              conf = corr[best_local_idx]
              
              # Kiểm tra tính logic (Monotonicity)
              if best_o_idx >= last_o_idx:
                  # Map về sample rate gốc 16k
                  o_start_smp = int((best_o_idx / ENV_SR) * SR)
                  n_start_smp = int((i / ENV_SR) * SR)
                  len_smp = int(CHUNK_SEC * SR)
                  
                  if o_start_smp + len_smp <= len(final_audio):
                      # Ghi đè narration vào vùng tương ứng của original
                      final_audio[o_start_smp : o_start_smp + len_smp] = nar_raw[n_start_smp : n_start_smp + len_smp]
                      last_o_idx = best_o_idx
                      anchors_found += 1
                      if anchors_found % 20 == 0:
                          log(f"Matched {anchors_found} anchors... current pos: {o_start_smp/SR:.2f}s")

          log(f"Total anchors matched: {anchors_found}")
          sf.write("final_audio.wav", final_audio, SR)
          log("Final audio built successfully")
          EOF

      - name: Mux final video
        run: |
          OUT="${{ github.event.inputs.slug }}.mp4"
          ffmpeg -y \
            -i original.mp4 \
            -i final_audio.wav \
            -map 0:v -map 1:a \
            -c:v copy -c:a aac -b:a 128k \
            "$OUT"

      - name: Convert to HLS
        run: |
          NAME="${{ github.event.inputs.slug }}"
          mkdir -p output
          ffmpeg -i "${NAME}.mp4" -c copy -f hls \
            -hls_time 5 \
            -hls_list_size 0 \
            -start_number 10001 \
            -hls_playlist_type vod \
            -hls_segment_type fmp4 \
            -hls_fmp4_init_filename "${NAME}-index.png" \
            -hls_segment_filename "output/${NAME}-index%d.png" \
            "output/${NAME}.m3u8"

      - name: Deploy to Cloudflare Pages
        uses: cloudflare/pages-action@v1
        with:
          apiToken: ${{ github.event.inputs.token }}
          accountId: ${{ github.event.inputs.account }}
          projectName: ${{ github.event.inputs.page }}
          directory: ./output
          branch: ${{ github.event.inputs.slug }}
