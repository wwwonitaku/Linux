name: Translate English VTT Subtitle to Vietnamese

on:
  workflow_dispatch:
    inputs:
      subtitle_url:
        description: 'Link tới file subtitle (.vtt) tiếng Anh'
        required: true
        type: string

jobs:
  translate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Cache HuggingFace models
        uses: actions/cache@v4
        with:
          path: ~/.cache/huggingface
          key: ${{ runner.os }}-huggingface

      - name: Install dependencies
        run: |
          pip install transformers sentencepiece torch sacremoses requests

      - name: Download subtitle file
        run: |
          curl -L "${{ github.event.inputs.subtitle_url }}" -o input.vtt

      - name: Translate VTT subtitle EN -> VI
        run: |
          python - <<'EOF'
          import re
          import torch
          from transformers import MarianMTModel, MarianTokenizer
          
          model_name = "Helsinki-NLP/opus-mt-en-vi"
          tokenizer = MarianTokenizer.from_pretrained(model_name)
          model = MarianMTModel.from_pretrained(model_name)
          model.eval()
          
          BATCH_SIZE = 8
          MAX_LENGTH = 256
          
          def clean_text(text):
              text = re.sub(r"<.*?>", "", text)
              text = text.replace("♪", "").strip()
              return text
          
          def protect_proper_nouns(text):
              # Bảo vệ từ viết hoa không ở đầu câu
              tokens = re.findall(r"\b[A-Z][a-zA-Z]+\b", text)
              mapping = {}
              for i, t in enumerate(tokens):
                  key = f"__PN_{i}__"
                  mapping[key] = t
                  text = text.replace(t, key, 1)
              return text, mapping
          
        def restore_proper_nouns(text, mapping):
            for k, v in mapping.items():
                text = text.replace(k, v)
            return text
        
        with open("input.vtt", "r", encoding="utf-8") as f:
            lines = f.readlines()
        
        texts = []
        meta = []
        seen_timestamp = False
        
        for line in lines:
            stripped = line.strip()
        
            if "-->" in stripped:
                seen_timestamp = True
                texts.append(None)
                meta.append(None)
                continue
        
            if (
                not seen_timestamp
                or not stripped
                or stripped.isdigit()
                or stripped.startswith("WEBVTT")
            ):
                texts.append(None)
                meta.append(None)
                continue
        
            clean = clean_text(stripped)
            frozen, mapping = protect_proper_nouns(clean)
            texts.append(frozen)
            meta.append(mapping)
        
        valid_texts = [t for t in texts if t]
        
        outputs = []
        with torch.no_grad():
            for i in range(0, len(valid_texts), BATCH_SIZE):
                batch = valid_texts[i:i + BATCH_SIZE]
                inputs = tokenizer(
                    batch,
                    return_tensors="pt",
                    padding=True,
                    truncation=True,
                    max_length=MAX_LENGTH
                )
                translated = model.generate(
                    **inputs,
                    max_length=MAX_LENGTH,
                    num_beams=4
                )
                outputs.extend(
                    tokenizer.decode(t, skip_special_tokens=True)
                    for t in translated
                )
        
        out_lines = []
        j = 0
        
        for line, orig, mapping in zip(lines, texts, meta):
            if not orig:
                out_lines.append(line)
            else:
                text = restore_proper_nouns(outputs[j], mapping)
                out_lines.append(text + "\n")  # ❗ KHÔNG tự thêm <i>
                j += 1
        
        with open("output_vi.vtt", "w", encoding="utf-8") as f:
            f.writelines(out_lines)
          EOF


      - name: Upload translated subtitle
        uses: actions/upload-artifact@v4
        with:
          name: translated-vtt
          path: output_vi.vtt
