name: Translate English VTT Subtitle to Vietnamese

on:
  workflow_dispatch:
    inputs:
      subtitle_url:
        description: 'Link tới file subtitle (.vtt) tiếng Anh'
        required: true
        type: string

jobs:
  translate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Cache HuggingFace models
        uses: actions/cache@v4
        with:
          path: ~/.cache/huggingface
          key: ${{ runner.os }}-huggingface

      - name: Install dependencies
        run: |
          pip install transformers sentencepiece torch sacremoses requests

      - name: Download subtitle file
        run: |
          curl -L "${{ github.event.inputs.subtitle_url }}" -o input.vtt

      - name: Translate VTT subtitle EN -> VI
        run: |
          python - <<'EOF'
          import re
          import torch
          from transformers import MarianMTModel, MarianTokenizer

          model_name = "Helsinki-NLP/opus-mt-en-vi"
          tokenizer = MarianTokenizer.from_pretrained(model_name)
          model = MarianMTModel.from_pretrained(model_name)
          model.eval()

          BATCH_SIZE = 8
          MAX_LENGTH = 256

          def clean_text(text):
              text = re.sub(r"<.*?>", "", text)
              text = text.replace("♪", "").strip()
              return text

          def protect_proper_nouns(text):
              words = text.split()
              protected = []
              for w in words:
                  if w[:1].isupper():
                      protected.append(f"@@{w}@@")
                  else:
                      protected.append(w)
              return " ".join(protected)

          def restore_proper_nouns(text):
              return re.sub(r"@@(.*?)@@", r"\1", text)

          with open("input.vtt", "r", encoding="utf-8") as f:
              lines = f.readlines()

          texts = []
          for line in lines:
              stripped = line.strip()

              if stripped == "WEBVTT":
                  texts.append(None)
              elif stripped and not stripped.isdigit() and "-->" not in stripped:
                  cleaned = clean_text(stripped)
                  texts.append(protect_proper_nouns(cleaned) if cleaned else None)
              else:
                  texts.append(None)

          valid_texts = [t for t in texts if t]

          outputs = []
          if valid_texts:
              with torch.no_grad():
                  for i in range(0, len(valid_texts), BATCH_SIZE):
                      batch = valid_texts[i:i + BATCH_SIZE]
                      inputs = tokenizer(
                          batch,
                          return_tensors="pt",
                          padding=True,
                          truncation=True,
                          max_length=MAX_LENGTH
                      )
                      translated = model.generate(
                          **inputs,
                          max_length=MAX_LENGTH,
                          num_beams=4
                      )
                      decoded = [
                          restore_proper_nouns(
                              tokenizer.decode(t, skip_special_tokens=True)
                          )
                          for t in translated
                      ]
                      outputs.extend(decoded)

          out_lines = []
          j = 0
          for line, orig in zip(lines, texts):
              if orig:
                  out_lines.append(line.replace(line.strip(), outputs[j]))
                  j += 1
              else:
                  out_lines.append(line)

          with open("output_vi.vtt", "w", encoding="utf-8") as f:
              f.writelines(out_lines)
          EOF

      - name: Upload translated subtitle
        uses: actions/upload-artifact@v4
        with:
          name: translated-vtt
          path: output_vi.vtt
