name: AHiHi -> CF

on:
  workflow_dispatch:
    inputs:
      type: { description: "Type", required: true }
      slug: { description: "Slug", required: true }
      ss: { description: "Season", required: true }
      ep: { description: "Ep", required: true }
      hid: { description: "Hid", required: true }
      token: { description: 'Token', required: true }
      page: { description: 'Page', required: true }
      account: { description: 'AID', required: true }
      key: { description: 'Key', required: true }

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Setup Environment
        run: |
          sudo apt update
          sudo apt install -y ffmpeg curl jq unzip fontconfig python3 python3-pip
          python3 -m pip install --upgrade pip
          python3 -m pip install webvtt-py requests edge-tts

      - name: Setup Subtitle Font (Oswald)
        run: |
          mkdir -p fonts
          curl -L https://github.com/phimmoitop/AHiHi/raw/main/Oswald.zip -o oswald.zip
          unzip -o oswald.zip -d fonts
          fc-cache -f fonts

      - name: Get download & subtitle link
        run: |
          HID="${{ github.event.inputs.hid }}"
          EP="${{ github.event.inputs.ep }}"
          RESP1=$(curl -s "https://hihianimeapi.onrender.com/api/v1/episodes/a-${HID}")
          LINK_EP=$(echo "$RESP1" | jq -r ".data[] | select(.episodeNumber == ($EP|tonumber)) | .id")
          RESP2=$(curl -s "https://hihianimeapi.onrender.com/api/v1/stream?type=sub&server=hd-2&id=${LINK_EP}")
          echo "LINK_DL=$(echo "$RESP2" | jq -r '.data.link.file')" >> $GITHUB_ENV
          echo "LINK_SUB=$(echo "$RESP2" | jq -r '.data.tracks[]? | select(.label=="English") | .file' | head -n1)" >> $GITHUB_ENV

      - name: Download Video & Subtitle
        run: |
          ffmpeg -y -i "$LINK_DL" -c copy -bsf:a aac_adtstoasc raw_video.mp4
          curl -L "$LINK_SUB" -o eng.vtt

      - name: AI Translate + TTS (Fixed Stability)
        env:
          GEMINI_API_KEY: ${{ github.event.inputs.key }}
        run: |
          python3 <<'EOF'
          import webvtt, os, time, re, requests, asyncio, edge_tts, subprocess

          API_KEY = os.environ['GEMINI_API_KEY']
          MAX_CONCURRENT_TTS = 5 

          def get_model():
              try:
                  res = requests.get(f"https://generativelanguage.googleapis.com/v1/models?key={API_KEY}").json()
                  # Ưu tiên Gemini 2.5 theo đúng bản chuẩn của bạn
                  for t in ['gemini-2.5-flash','gemini-2.0-flash','gemini-1.5-flash']:
                      for m in res.get('models', []):
                          if t in m['name']: return m['name']
                  return res['models'][0]['name']
              except: return "gemini-1.5-flash"

          def safe_text(text, max_len=450):
              text = re.sub(r'\s+', ' ', text).strip()
              return text if len(text) <= max_len else text[:max_len] + "..."

          def normalize_for_tts(text):
              text = re.sub(r'\s+', ' ', text).strip()
              text = text.replace(",", ", ").replace(".", ". ").replace("?", "? ").replace("!", "! ")
              text = text.replace("…", " ... ").replace("—", " ... ")
              if not text.endswith((".", "!", "?", "...")): text += "."
              return text

          async def generate_tts(text, out, idx, semaphore):
              async with semaphore:
                  try:
                      tts_text = normalize_for_tts(text)
                      tts = edge_tts.Communicate(tts_text, voice="vi-VN-HoaiMyNeural", rate="+27%")
                      await tts.save(out)
                      if not os.path.exists(out) or os.path.getsize(out) < 100: raise Exception("Fail")
                      print(f"[TTS OK] #{idx}")
                  except:
                      print(f"[TTS RETRY] #{idx}")
                      await asyncio.sleep(2)
                      try:
                          tts = edge_tts.Communicate(normalize_for_tts(text), voice="vi-VN-HoaiMyNeural", rate="+27%")
                          await tts.save(out)
                      except:
                          subprocess.run(["ffmpeg","-y","-f","lavfi","-i","anullsrc=r=24000:cl=mono","-t","0.1",out], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

          async def main():
              model = get_model()
              print(f"Using model: {model}")
              vtt = webvtt.read("eng.vtt")
              total = len(vtt)
              all_vi = [None] * total

              for i in range(0, total, 120):
                  batch = vtt[i:i+120]
                  prompt = "Bạn là biên dịch viên Anime chuyên nghiệp. QUY TẮC XƯNG HÔ QUAN TRỌNG: Xác định giới tính dựa vào ngữ cảnh câu lệnh (VD: "Beautiful girl", "He", "She"). Cặp đôi/Bạn bè khác giới: Anh - Em (nếu thân mật) hoặc Tớ - Cậu. Nam - Nam: Tôi - Cậu, Tớ - Cậu hoặc Tao - Mày (nếu ghét nhau). Nữ - Nữ: Mình - Cậu, Chị - Em. Kẻ thù: Ta - Ngươi. Người lớn tuổi: Chú/Cô/Ông/Bà - Cháu. TUYỆT ĐỐI KHÔNG: Để nữ xưng "anh", nam xưng "em" (trừ khi là hậu bối gọi tiền bối). Văn phong: Giữ phong cách Anime Nhật Bản (biểu cảm, tự nhiên). Giữ định dạng ID: Nội dung.\n\n"
                  prompt += "\n".join(f"{i+j}: {c.text.replace(chr(10),' ')}" for j, c in enumerate(batch))
                  try:
                      url = f"https://generativelanguage.googleapis.com/v1beta/{model}:generateContent?key={API_KEY}"
                      # Thêm SafetySettings để tránh bị chặn dịch các cảnh nhạy cảm
                      r = requests.post(url, json={
                          "contents":[{"parts":[{"text":prompt}]}],
                          "safetySettings": [{"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"}, {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"}, {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"}, {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}]
                      }, timeout=60)
                      txt = r.json()["candidates"][0]["content"]["parts"][0]["text"]
                      # Xóa Markdown nếu AI tự thêm
                      txt = re.sub(r'```.*?```', '', txt, flags=re.DOTALL)
                      for line in txt.splitlines():
                          m = re.match(r'^(\d+):\s*(.+)', line.strip())
                          if m:
                              idx = int(m.group(1))
                              if 0 <= idx < total: all_vi[idx] = m.group(2)
                  except: pass
                  time.sleep(1)

              os.makedirs("chunks", exist_ok=True)
              vi_vtt = webvtt.WebVTT()
              semaphore = asyncio.Semaphore(MAX_CONCURRENT_TTS)
              tasks = []

              for i, c in enumerate(vtt):
                  raw = all_vi[i] if all_vi[i] else c.text.replace('\n', ' ')
                  txt = safe_text(raw)
                  vi_vtt.captions.append(webvtt.Caption(c.start, c.end, txt))
                  tasks.append(generate_tts(txt, f"chunks/c_{i}.mp3", i, semaphore))

              await asyncio.gather(*tasks)
              vi_vtt.save("vi.vtt")
              with open("count.txt", "w") as f: f.write(str(total))

          asyncio.run(main())
          EOF

      - name: Build Filter
        run: |
          python3 <<EOF
          import webvtt
          vtt = webvtt.read("vi.vtt")
          with open("master_filter.txt","w") as f:
              for i,c in enumerate(vtt):
                  h,m,s = c.start.replace(',','.').split(':')
                  ms = int(float(h)*3600000 + float(m)*60000 + float(s)*1000) + 300
                  f.write(f"[{i+1}:a]adelay={ms}|{ms}[a{i}];")
              f.write("".join(f"[a{i}]" for i in range(len(vtt))))
              f.write(f"amix=inputs={len(vtt)}:normalize=0,volume=2.0[tts];")
              f.write("[0:a]volume=0.75[bg];[bg][tts]amix=inputs=2[out_audio];")
              f.write("[0:v]subtitles=vi.vtt:fontsdir=fonts:force_style='FontName=Oswald,PrimaryColour=&H00FFFF&,FontSize=30,Outline=0.8,Shadow=0.5'[out_video]")
          EOF

      - name: Render & HLS
        run: |
          NAME="${{ github.event.inputs.type }}-${{ github.event.inputs.slug }}-${{ github.event.inputs.ss }}-${{ github.event.inputs.ep }}"
          COUNT=$(cat count.txt)
          
          # FIX QUAN TRỌNG: Nạp file audio theo đúng thứ tự c_0, c_1, c_2...
          INPUTS="-i raw_video.mp4"
          for ((i=0; i<COUNT; i++)); do
            INPUTS="$INPUTS -i chunks/c_$i.mp3"
          done

          ffmpeg -y $INPUTS -filter_complex_script master_filter.txt \
            -map "[out_video]" -map "[out_audio]" \
            -c:v libx264 -crf 22 -preset fast \
            -c:a aac -b:a 128k final.mp4

          mkdir -p output
          ffmpeg -i final.mp4 -c copy -f hls \
            -hls_time 5 -hls_list_size 0 -start_number 10001 -hls_playlist_type vod \
            -hls_segment_type fmp4 \
            -hls_fmp4_init_filename "${NAME}-index.png" \
            -hls_segment_filename "output/${NAME}-index%d.png" \
            "output/${NAME}.m3u8"
          cp vi.vtt output/

      - name: Deploy to Cloudflare Pages
        uses: cloudflare/pages-action@v1
        with:
          apiToken: ${{ github.event.inputs.token }}
          accountId: ${{ github.event.inputs.account }}
          projectName: ${{ github.event.inputs.page }}
          directory: ./output
          branch: ${{ github.event.inputs.type }}-${{ github.event.inputs.slug }}-${{ github.event.inputs.ss }}-${{ github.event.inputs.ep }}
